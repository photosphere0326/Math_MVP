from celery import current_task
from .celery_app import celery_app
from .database import SessionLocal
from .services.math_generation_service import MathGenerationService
from .schemas.math_generation import MathProblemGenerationRequest
from .models.worksheet import Worksheet, WorksheetStatus
from .models.math_generation import MathProblemGeneration
from .models.problem import Problem
import json
import uuid
from datetime import datetime
from sqlalchemy.orm import Session


@celery_app.task(bind=True, name="app.tasks.generate_math_problems_task")
def generate_math_problems_task(self, request_data: dict, user_id: int):
    """ë¹„ë™ê¸° ìˆ˜í•™ ë¬¸ì œ ìƒì„± íƒœìŠ¤í¬"""
    
    # íƒœìŠ¤í¬ ID ìƒì„±
    task_id = self.request.id
    generation_id = str(uuid.uuid4())
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ìƒì„±
    db = SessionLocal()
    
    try:
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 0, 'total': 100, 'status': 'ë¬¸ì œ ìƒì„± ì¤€ë¹„ ì¤‘...'}
        )
        
        # ìš”ì²­ ë°ì´í„°ë¥¼ Pydantic ëª¨ë¸ë¡œ ë³€í™˜
        request = MathProblemGenerationRequest.model_validate(request_data)
        
        # ì›Œí¬ì‹œíŠ¸ ì´ˆê¸° ìƒì„± (PROCESSING ìƒíƒœ)
        worksheet_title = f"{request.chapter.chapter_name} - {request.problem_count.value}"
        worksheet = Worksheet(
            title=worksheet_title,
            school_level=request.school_level.value,
            grade=request.grade,
            semester=request.semester.value,
            unit_number=request.unit_number,
            unit_name=request.chapter.unit_name,
            chapter_number=request.chapter.chapter_number,
            chapter_name=request.chapter.chapter_name,
            problem_count=request.problem_count.value_int,
            difficulty_ratio=request.difficulty_ratio.model_dump(),
            problem_type_ratio=request.problem_type_ratio.model_dump(),
            user_prompt=request.user_text,
            generation_id=generation_id,
            status=WorksheetStatus.PROCESSING,
            created_by=user_id,
            celery_task_id=task_id
        )
        
        db.add(worksheet)
        db.flush()
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 20, 'total': 100, 'status': 'êµìœ¡ê³¼ì • ë°ì´í„° ë¡œë“œ ì¤‘...'}
        )
        
        # MathGenerationService ì´ˆê¸°í™”
        math_service = MathGenerationService()
        
        # êµìœ¡ê³¼ì • ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        curriculum_data = math_service._get_curriculum_data(request)
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 40, 'total': 100, 'status': 'ë¬¸ì œ ìœ í˜• ë¶„ì„ ì¤‘...'}
        )
        
        # ë¬¸ì œ ìœ í˜• ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        problem_types = math_service._get_problem_types(request.chapter.chapter_name)
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 60, 'total': 100, 'status': 'AIë¡œ ë¬¸ì œ ìƒì„± ì¤‘...'}
        )
        
        # AI ì„œë¹„ìŠ¤ë¥¼ í†µí•œ ë¬¸ì œ ìƒì„±
        generated_problems = math_service._generate_problems_with_ai(
            curriculum_data=curriculum_data,
            problem_types=problem_types,
            request=request
        )
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 80, 'total': 100, 'status': 'ë¬¸ì œ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...'}
        )
        
        # ìƒì„± ì„¸ì…˜ ì €ì¥
        generation_session = MathProblemGeneration(
            generation_id=generation_id,
            school_level=request.school_level.value,
            grade=request.grade,
            semester=request.semester.value,
            unit_number=request.unit_number,
            unit_name=request.chapter.unit_name,
            chapter_number=request.chapter.chapter_number,
            chapter_name=request.chapter.chapter_name,
            problem_count=request.problem_count.value_int,
            difficulty_ratio=request.difficulty_ratio.model_dump(),
            problem_type_ratio=request.problem_type_ratio.model_dump(),
            user_text=request.user_text,
            actual_difficulty_distribution=math_service._calculate_difficulty_distribution(generated_problems),
            actual_type_distribution=math_service._calculate_type_distribution(generated_problems),
            total_generated=len(generated_problems),
            created_by=user_id
        )
        
        db.add(generation_session)
        db.flush()
        
        # ìƒì„±ëœ ë¬¸ì œë“¤ì„ ì›Œí¬ì‹œíŠ¸ì— ì—°ê²°í•˜ì—¬ ì €ì¥
        problem_responses = []
        for i, problem_data in enumerate(generated_problems):
            problem = Problem(
                worksheet_id=worksheet.id,
                sequence_order=i + 1,
                problem_type=problem_data.get("problem_type", "multiple_choice"),
                difficulty=problem_data.get("difficulty", "B"),
                question=problem_data.get("question", ""),
                choices=json.dumps(problem_data.get("choices")) if problem_data.get("choices") else None,
                correct_answer=problem_data.get("correct_answer", ""),
                explanation=problem_data.get("explanation", ""),
                latex_content=problem_data.get("latex_content"),
                has_diagram=str(problem_data.get("has_diagram", False)).lower(),
                diagram_type=problem_data.get("diagram_type"),
                diagram_elements=json.dumps(problem_data.get("diagram_elements")) if problem_data.get("diagram_elements") else None
            )
            
            db.add(problem)
            db.flush()
            
            # GeneratedProblemSet ì œê±°ë¨ - Problem í…Œì´ë¸”ì˜ sequence_orderë¡œ ëŒ€ì²´
            
            # ì‘ë‹µìš© ë°ì´í„° ìƒì„±
            problem_responses.append({
                "id": problem.id,
                "sequence_order": i + 1,
                "problem_type": problem.problem_type,
                "difficulty": problem.difficulty,
                "question": problem.question,
                "choices": json.loads(problem.choices) if problem.choices else None,
                "correct_answer": problem.correct_answer,
                "explanation": problem.explanation,
                "latex_content": problem.latex_content,
                "has_diagram": problem.has_diagram == "true",
                "diagram_type": problem.diagram_type,
                "diagram_elements": json.loads(problem.diagram_elements) if problem.diagram_elements else None
            })
        
        # ì›Œí¬ì‹œíŠ¸ ì™„ë£Œ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
        worksheet.actual_difficulty_distribution = math_service._calculate_difficulty_distribution(generated_problems)
        worksheet.actual_type_distribution = math_service._calculate_type_distribution(generated_problems)
        worksheet.status = WorksheetStatus.COMPLETED
        worksheet.completed_at = datetime.now()
        
        db.commit()
        
        # ì„±ê³µ ê²°ê³¼ ë°˜í™˜
        result = {
            "generation_id": generation_id,
            "worksheet_id": worksheet.id,
            "school_level": request.school_level.value,
            "grade": request.grade,
            "semester": request.semester.value,
            "unit_name": request.chapter.unit_name,
            "chapter_name": request.chapter.chapter_name,
            "problem_count": request.problem_count.value_int,
            "difficulty_ratio": request.difficulty_ratio.model_dump(),
            "problem_type_ratio": request.problem_type_ratio.model_dump(),
            "user_prompt": request.user_text,
            "actual_difficulty_distribution": math_service._calculate_difficulty_distribution(generated_problems),
            "actual_type_distribution": math_service._calculate_type_distribution(generated_problems),
            "problems": problem_responses,
            "total_generated": len(generated_problems),
            "created_at": datetime.now().isoformat()
        }
        
        return result
        
    except Exception as e:
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›Œí¬ì‹œíŠ¸ ìƒíƒœë¥¼ FAILEDë¡œ ë³€ê²½
        if 'worksheet' in locals():
            worksheet.status = WorksheetStatus.FAILED
            worksheet.error_message = str(e)
            db.commit()
        
        # íƒœìŠ¤í¬ ì‹¤íŒ¨ ìƒíƒœë¡œ ì—…ë°ì´íŠ¸
        self.update_state(
            state='FAILURE',
            meta={'error': str(e), 'status': 'ë¬¸ì œ ìƒì„± ì‹¤íŒ¨'}
        )
        raise
        
    finally:
        db.close()


@celery_app.task(bind=True, name="app.tasks.grade_problems_mixed_task")
def grade_problems_mixed_task(self, worksheet_id: int, multiple_choice_answers: dict, canvas_answers: dict, user_id: int, handwritten_image_data: dict = None):
    """í˜¼í•©í˜• ì±„ì  íƒœìŠ¤í¬ - ê°ê´€ì‹: ì²´í¬ë°•ìŠ¤, ì„œìˆ í˜•/ë‹¨ë‹µí˜•: OCR"""
    
    task_id = self.request.id
    db = SessionLocal()
    
    try:
        from .services.ai_service import AIService
        ai_service = AIService()
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 0, 'total': 100, 'status': 'ì±„ì  ì¤€ë¹„ ì¤‘...'}
        )
        
        # ì›Œí¬ì‹œíŠ¸ì™€ ë¬¸ì œë“¤ ì¡°íšŒ
        worksheet = db.query(Worksheet).filter(Worksheet.id == worksheet_id).first()
        if not worksheet:
            raise ValueError("ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        problems = db.query(Problem).filter(Problem.worksheet_id == worksheet_id).all()
        total_count = len(problems)
        
        # ë¬¸ì œìˆ˜ì— ë”°ë¥¸ ë°°ì  ê³„ì‚°
        points_per_problem = 10 if total_count == 10 else 5 if total_count == 20 else 100 // total_count
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 10, 'total': 100, 'status': 'OCRë¡œ ì†ê¸€ì”¨ ë‹µì•ˆ ì¶”ì¶œ ì¤‘...'}
        )
        
        # ê° ë¬¸ì œë³„ OCR ê²°ê³¼ ì €ì¥
        ocr_results = {}
        if canvas_answers:
            import base64
            for problem_id, canvas_data in canvas_answers.items():
                if canvas_data and canvas_data.startswith('data:image/png;base64,'):
                    try:
                        # base64 ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                        image_data = canvas_data.split(',')[1]
                        handwritten_image_data = base64.b64decode(image_data)
                        
                        # ë¬¸ì œë³„ OCR ì²˜ë¦¬
                        raw_ocr_text = ai_service.ocr_handwriting(handwritten_image_data)
                        normalized_ocr_text = _normalize_fraction_text(raw_ocr_text)
                        ocr_results[problem_id] = normalized_ocr_text
                        print(f"ğŸ” ë””ë²„ê·¸: ë¬¸ì œ {problem_id} OCR ì›ë³¸: {raw_ocr_text[:50]}...")
                        print(f"ğŸ” ë””ë²„ê·¸: ë¬¸ì œ {problem_id} OCR ì •ê·œí™”: {normalized_ocr_text[:50]}...")
                    except Exception as e:
                        print(f"ğŸ” OCR ì˜¤ë¥˜ (ë¬¸ì œ {problem_id}): {str(e)}")
                        ocr_results[problem_id] = ""
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 20, 'total': 100, 'status': 'ë‹µì•ˆ ë¶„ì„ ë° ì±„ì  ì¤‘...'}
        )
        
        # ì±„ì  ê²°ê³¼ ì €ì¥
        grading_results = []
        correct_count = 0
        total_score = 0
        
        for i, problem in enumerate(problems):
            if problem.problem_type == "multiple_choice":
                # ê°ê´€ì‹: ì²´í¬ë°•ìŠ¤ë¡œ ë°›ì€ ë‹µì•ˆ ì‚¬ìš©
                user_answer = multiple_choice_answers.get(str(problem.id), "")
                result = _grade_objective_problem(problem, user_answer, points_per_problem)
                result["input_method"] = "checkbox"
            else:
                # ì„œìˆ í˜•/ë‹¨ë‹µí˜•: í•´ë‹¹ ë¬¸ì œì˜ ê°œë³„ OCR ê²°ê³¼ ì‚¬ìš©
                user_answer = ocr_results.get(str(problem.id), "")
                print(f"ğŸ” ë””ë²„ê·¸: ë¬¸ì œ {problem.id} ë‹µì•ˆ: '{user_answer}'")
                
                if problem.problem_type == "essay":
                    result = _grade_essay_problem(ai_service, problem, user_answer, points_per_problem)
                else:  # short_answer
                    result = _grade_objective_problem(problem, user_answer, points_per_problem)
                result["input_method"] = "handwriting_ocr"
            
            grading_results.append(result)
            
            if result["is_correct"]:
                correct_count += 1
            total_score += result.get("score", 0)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = 20 + (i + 1) / total_count * 70
            self.update_state(
                state='PROGRESS',
                meta={'current': progress, 'total': 100, 'status': f'ì±„ì  ì¤‘... ({i+1}/{total_count})'}
            )
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 95, 'total': 100, 'status': 'ê²°ê³¼ ì €ì¥ ì¤‘...'}
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì±„ì  ê²°ê³¼ ì €ì¥
        from .models.grading_result import GradingSession, ProblemGradingResult
        
        grading_session = GradingSession(
            worksheet_id=worksheet_id,
            celery_task_id=task_id,
            total_problems=total_count,
            correct_count=correct_count,
            total_score=total_score,
            max_possible_score=total_count * points_per_problem,
            points_per_problem=points_per_problem,
            ocr_results=ocr_results,
            multiple_choice_answers=multiple_choice_answers,
            input_method="canvas",
            graded_by=user_id
        )
        
        db.add(grading_session)
        db.flush()
        
        # ë¬¸ì œë³„ ì±„ì  ê²°ê³¼ ì €ì¥
        for result_item in grading_results:
            problem_result = ProblemGradingResult(
                grading_session_id=grading_session.id,
                problem_id=result_item["problem_id"],
                user_answer=result_item.get("user_answer", ""),
                actual_user_answer=result_item.get("actual_user_answer", result_item.get("user_answer", "")),
                correct_answer=result_item["correct_answer"],
                is_correct=result_item["is_correct"],
                score=result_item["score"],
                points_per_problem=result_item["points_per_problem"],
                problem_type=result_item["problem_type"],
                input_method=result_item.get("input_method", "canvas"),
                ai_score=result_item.get("ai_score"),
                ai_feedback=result_item.get("ai_feedback"),
                strengths=result_item.get("strengths"),
                improvements=result_item.get("improvements"),
                keyword_score_ratio=result_item.get("keyword_score_ratio"),
                explanation=result_item.get("explanation", "")
            )
            db.add(problem_result)
        
        db.commit()
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            "grading_session_id": grading_session.id,
            "worksheet_id": worksheet_id,
            "total_problems": total_count,
            "correct_count": correct_count,
            "total_score": total_score,
            "points_per_problem": points_per_problem,
            "max_possible_score": total_count * points_per_problem,
            "ocr_results": ocr_results,
            "multiple_choice_answers": multiple_choice_answers,
            "grading_results": grading_results,
            "graded_at": datetime.now().isoformat()
        }
        
        return result
        
    except Exception as e:
        self.update_state(
            state='FAILURE',
            meta={'error': str(e), 'status': 'ì±„ì  ì‹¤íŒ¨'}
        )
        raise
        
    finally:
        db.close()


@celery_app.task(bind=True, name="app.tasks.grade_problems_task")
def grade_problems_task(self, worksheet_id: int, image_data: bytes, user_id: int):
    """ë¹„ë™ê¸° ë¬¸ì œ ì±„ì  íƒœìŠ¤í¬ - OCR ê¸°ë°˜ ì±„ì """
    
    task_id = self.request.id
    db = SessionLocal()
    
    try:
        from .services.ai_service import AIService
        ai_service = AIService()
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 0, 'total': 100, 'status': 'ì±„ì  ì¤€ë¹„ ì¤‘...'}
        )
        
        # ì›Œí¬ì‹œíŠ¸ì™€ ë¬¸ì œë“¤ ì¡°íšŒ
        worksheet = db.query(Worksheet).filter(Worksheet.id == worksheet_id).first()
        if not worksheet:
            raise ValueError("ì›Œí¬ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        problems = db.query(Problem).filter(Problem.worksheet_id == worksheet_id).all()
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 10, 'total': 100, 'status': 'OCRë¡œ ë‹µì•ˆ ì¶”ì¶œ ì¤‘...'}
        )
        
        # OCRë¡œ í•™ìƒ ë‹µì•ˆ ì¶”ì¶œ
        raw_ocr_text = ai_service.ocr_handwriting(image_data)
        if not raw_ocr_text:
            raise ValueError("ë‹µì•ˆì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # OCR í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ë¶„ìˆ˜ ì •ê·œí™”)
        ocr_text = _normalize_fraction_text(raw_ocr_text)
        print(f"ğŸ” OCR ì „ì²˜ë¦¬: '{raw_ocr_text}' â†’ '{ocr_text}'")
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 20, 'total': 100, 'status': 'ë‹µì•ˆ ë¶„ì„ ì¤‘...'}
        )
        
        # ì±„ì  ê²°ê³¼ ì €ì¥
        grading_results = []
        correct_count = 0
        total_score = 0
        total_count = len(problems)
        
        # ë¬¸ì œìˆ˜ì— ë”°ë¥¸ ë°°ì  ê³„ì‚°
        points_per_problem = 10 if total_count == 10 else 5 if total_count == 20 else 100 // total_count
        
        for i, problem in enumerate(problems):
            # OCR í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ë¬¸ì œì˜ ë‹µì•ˆ ì¶”ì¶œ (ê°„ë‹¨í•œ êµ¬í˜„)
            # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë‹µì•ˆ ë§¤ì¹­ ë¡œì§ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
            user_answer = _extract_answer_from_ocr(ocr_text, problem.id, i + 1)
            
            # ë¬¸ì œ ìœ í˜•ë³„ ì±„ì  ì²˜ë¦¬
            if problem.problem_type == "essay":
                # ì„œìˆ í˜•: 1ì°¨ í‚¤ì›Œë“œ ê²€ì‚¬ â†’ 2ì°¨ AI ì±„ì 
                result = _grade_essay_problem(ai_service, problem, user_answer, points_per_problem)
            else:
                # ê°ê´€ì‹/ë‹¨ë‹µí˜•: ì§ì ‘ ë¹„êµ
                result = _grade_objective_problem(problem, user_answer, points_per_problem)
            
            grading_results.append(result)
            
            if result["is_correct"]:
                correct_count += 1
            total_score += result.get("score", 0)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = 20 + (i + 1) / total_count * 70
            self.update_state(
                state='PROGRESS',
                meta={'current': progress, 'total': 100, 'status': f'ì±„ì  ì¤‘... ({i+1}/{total_count})'}
            )
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚° (ì´ì  ê¸°ì¤€)
        final_total_score = total_score
        
        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
        self.update_state(
            state='PROGRESS',
            meta={'current': 95, 'total': 100, 'status': 'ê²°ê³¼ ì €ì¥ ì¤‘...'}
        )
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì±„ì  ê²°ê³¼ ì €ì¥
        from .models.grading_result import GradingSession, ProblemGradingResult
        
        grading_session = GradingSession(
            worksheet_id=worksheet_id,
            celery_task_id=task_id,
            total_problems=total_count,
            correct_count=correct_count,
            total_score=final_total_score,
            max_possible_score=total_count * points_per_problem,
            points_per_problem=points_per_problem,
            ocr_text=ocr_text,
            input_method="image_upload",
            graded_by=user_id
        )
        
        db.add(grading_session)
        db.flush()
        
        # ë¬¸ì œë³„ ì±„ì  ê²°ê³¼ ì €ì¥
        for result_item in grading_results:
            problem_result = ProblemGradingResult(
                grading_session_id=grading_session.id,
                problem_id=result_item["problem_id"],
                user_answer=result_item.get("user_answer", ""),
                actual_user_answer=result_item.get("actual_user_answer", result_item.get("user_answer", "")),
                correct_answer=result_item["correct_answer"],
                is_correct=result_item["is_correct"],
                score=result_item["score"],
                points_per_problem=result_item["points_per_problem"],
                problem_type=result_item["problem_type"],
                input_method="handwriting_ocr",
                ai_score=result_item.get("ai_score"),
                ai_feedback=result_item.get("ai_feedback"),
                strengths=result_item.get("strengths"),
                improvements=result_item.get("improvements"),
                keyword_score_ratio=result_item.get("keyword_score_ratio"),
                explanation=result_item.get("explanation", "")
            )
            db.add(problem_result)
        
        db.commit()
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            "grading_session_id": grading_session.id,
            "worksheet_id": worksheet_id,
            "total_problems": total_count,
            "correct_count": correct_count,
            "total_score": final_total_score,
            "points_per_problem": points_per_problem,
            "max_possible_score": total_count * points_per_problem,
            "ocr_text": ocr_text,
            "grading_results": grading_results,
            "graded_at": datetime.now().isoformat()
        }
        
        return result
        
    except Exception as e:
        self.update_state(
            state='FAILURE',
            meta={'error': str(e), 'status': 'ì±„ì  ì‹¤íŒ¨'}
        )
        raise
        
    finally:
        db.close()


def _normalize_fraction_text(text: str) -> str:
    """OCR í…ìŠ¤íŠ¸ì—ì„œ ì„¸ë¡œ ë¶„ìˆ˜ íŒ¨í„´ì„ ì°¾ì•„ì„œ í‘œì¤€ í˜•íƒœë¡œ ë³€í™˜"""
    import re
    from fractions import Fraction
    
    # ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ë‰œ ë¶„ìˆ˜ íŒ¨í„´ ì°¾ê¸°
    lines = text.split('\n')
    normalized_lines = []
    
    i = 0
    while i < len(lines):
        current_line = lines[i].strip()
        
        # ë¶„ìˆ˜ íŒ¨í„´ ì°¾ê¸°: ìˆ«ì â†’ ì„ (-, â€•, â€”) â†’ ìˆ«ì
        if (i + 2 < len(lines) and 
            re.match(r'^\s*\d+\s*$', current_line) and  # ì²« ì¤„: ìˆ«ìë§Œ
            re.match(r'^\s*[-â€•â€”_]+\s*$', lines[i + 1].strip()) and  # ë‘˜ì§¸ ì¤„: ì„ 
            re.match(r'^\s*\d+\s*$', lines[i + 2].strip())):  # ì…‹ì§¸ ì¤„: ìˆ«ìë§Œ
            
            numerator = current_line
            denominator = lines[i + 2].strip()
            
            # í‘œì¤€ ë¶„ìˆ˜ í˜•íƒœë¡œ ë³€í™˜
            fraction_text = f"{numerator}/{denominator}"
            
            print(f"ğŸ” ì„¸ë¡œ ë¶„ìˆ˜ ë°œê²¬: {numerator} over {denominator} â†’ {fraction_text}")
            normalized_lines.append(fraction_text)
            i += 3  # 3ì¤„ì„ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
            continue
        
        # ë¶„ìˆ˜ê°€ ì•„ë‹Œ ê²½ìš° ê·¸ëŒ€ë¡œ ì¶”ê°€
        normalized_lines.append(current_line)
        i += 1
    
    # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ìˆ«ìë“¤ì„ ë¶„ìˆ˜ë¡œ ë³€í™˜í•˜ê¸° (ì˜ˆ: "2 7" â†’ "2/7")
    result_text = ' '.join(normalized_lines)
    
    # ì—°ì†ëœ ë‘ ìˆ«ì ì‚¬ì´ì— ê³µë°±ì´ ìˆëŠ” ê²½ìš° ë¶„ìˆ˜ë¡œ í•´ì„
    # ë‹¨, ë¬¸ë§¥ìƒ ë¶„ìˆ˜ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì€ ê²½ìš°ë§Œ (ì‘ì€ ìˆ«ìë“¤)
    def replace_space_fractions(match):
        num1, num2 = match.groups()
        # ë‘ ìˆ«ì ëª¨ë‘ 10 ì´í•˜ì¸ ê²½ìš°ë§Œ ë¶„ìˆ˜ë¡œ ë³€í™˜
        if int(num1) <= 20 and int(num2) <= 20:
            return f"{num1}/{num2}"
        return match.group(0)  # ì›ë˜ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ
    
    result_text = re.sub(r'(\d+)\s+(\d+)(?!\d)', replace_space_fractions, result_text)
    
    return result_text

def _normalize_answer_for_comparison(answer: str) -> str:
    """ë‹µì•ˆì„ ë¹„êµìš©ìœ¼ë¡œ ì •ê·œí™”"""
    import re
    from fractions import Fraction
    
    answer = answer.strip().lower()
    
    # ë¶„ìˆ˜ í‘œí˜„ì„ ì°¾ì•„ì„œ ê¸°ì•½ë¶„ìˆ˜ë¡œ ë³€í™˜
    fraction_patterns = [
        r'(\d+)/(\d+)',  # 2/7
        r'(\d+)ë¶„ì˜(\d+)',  # 7ë¶„ì˜2
        r'(\d+) *ë¶„ì˜ *(\d+)',  # 7 ë¶„ì˜ 2
    ]
    
    def normalize_fraction(match):
        if 'ë¶„ì˜' in match.group(0):
            # 'ë¶„ì˜' íŒ¨í„´: ë¶„ëª¨ê°€ ë¨¼ì € ì˜¨ë‹¤
            denominator = int(match.group(1))
            numerator = int(match.group(2))
        else:
            # ì¼ë°˜ ë¶„ìˆ˜: ë¶„ìê°€ ë¨¼ì € ì˜¨ë‹¤
            numerator = int(match.group(1))
            denominator = int(match.group(2))
        
        try:
            frac = Fraction(numerator, denominator)
            return f"{frac.numerator}/{frac.denominator}"
        except:
            return match.group(0)
    
    for pattern in fraction_patterns:
        answer = re.sub(pattern, normalize_fraction, answer)
    
    return answer

def _extract_answer_from_ocr(ocr_text: str, problem_id: int, problem_number: int) -> str:
    """OCR í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì • ë¬¸ì œì˜ ë‹µì•ˆì„ ì¶”ì¶œ"""
    # ê°„ë‹¨í•œ êµ¬í˜„: ë¬¸ì œ ë²ˆí˜¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹µì•ˆ ì¶”ì¶œ
    # ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒ¨í„´ ë§¤ì¹­ì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
    lines = ocr_text.split('\n')
    
    # ë¬¸ì œ ë²ˆí˜¸ íŒ¨í„´ ì°¾ê¸°
    for i, line in enumerate(lines):
        if f"{problem_number}." in line or f"{problem_number})" in line:
            # í•´ë‹¹ ì¤„ì—ì„œ ë‹µì•ˆ ë¶€ë¶„ ì¶”ì¶œ
            answer_part = line.split(f"{problem_number}.")[-1].split(f"{problem_number})")[-1]
            return answer_part.strip()
    
    # íŒ¨í„´ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
    return ocr_text.strip()


def _grade_essay_problem(ai_service, problem: Problem, user_answer: str, points_per_problem: int) -> dict:
    """ì„œìˆ í˜• ë¬¸ì œ ì±„ì : 1ì°¨ í‚¤ì›Œë“œ ê²€ì‚¬ â†’ 2ì°¨ AI ì±„ì """
    
    # 1ì°¨ ì±„ì : í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
    correct_answer_keywords = problem.correct_answer.lower().split()
    user_answer_lower = user_answer.lower()
    
    keyword_matches = 0
    for keyword in correct_answer_keywords:
        if keyword in user_answer_lower:
            keyword_matches += 1
    
    keyword_score_ratio = (keyword_matches / len(correct_answer_keywords)) if correct_answer_keywords else 0
    
    # 2ì°¨ ì±„ì : AI ì‹¬ì¸µ ë¶„ì„
    ai_result = ai_service.grade_math_answer(
        question=problem.question,
        correct_answer=problem.correct_answer,
        student_answer=user_answer,
        explanation=problem.explanation,
        problem_type="essay"
    )
    
    # ìµœì¢… ì ìˆ˜: AI ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì œë³„ ë°°ì  ì ìš©
    ai_score_ratio = ai_result.get("score", 0) / 100
    final_score = points_per_problem * ai_score_ratio
    
    return {
        "problem_id": problem.id,
        "problem_type": "essay",
        "user_answer": user_answer,
        "correct_answer": problem.correct_answer,
        "is_correct": final_score >= (points_per_problem * 0.6),  # 60% ì´ìƒì´ë©´ ì •ë‹µ
        "score": final_score,
        "points_per_problem": points_per_problem,
        "keyword_score_ratio": keyword_score_ratio,
        "ai_score": ai_result.get("score", 0),
        "ai_feedback": ai_result.get("feedback", ""),
        "strengths": ai_result.get("strengths", ""),
        "improvements": ai_result.get("improvements", ""),
        "explanation": problem.explanation
    }


def _grade_objective_problem(problem: Problem, user_answer: str, points_per_problem: int) -> dict:
    """ê°ê´€ì‹/ë‹¨ë‹µí˜• ë¬¸ì œ ì±„ì : ì§ì ‘ ë¹„êµ"""
    
    # ê°ê´€ì‹ì¸ ê²½ìš° ì„ íƒì§€ ì¸ë±ìŠ¤ë¥¼ ì‹¤ì œ ì„ íƒì§€ ë‚´ìš©ìœ¼ë¡œ ë³€í™˜
    actual_user_answer = user_answer
    if problem.problem_type == "multiple_choice" and problem.choices:
        # A, B, C, Dë¥¼ 0, 1, 2, 3 ì¸ë±ìŠ¤ë¡œ ë³€í™˜
        choice_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3}
        if user_answer.upper() in choice_map:
            try:
                import json
                choices = json.loads(problem.choices)
                choice_index = choice_map[user_answer.upper()]
                if 0 <= choice_index < len(choices):
                    actual_user_answer = choices[choice_index]
            except (json.JSONDecodeError, IndexError):
                pass  # ë³€í™˜ ì‹¤íŒ¨ì‹œ ì›ë˜ ë‹µì•ˆ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    
    # ë‹µì•ˆ ì •ê·œí™” ë° ë¹„êµ (ë¶„ìˆ˜ ì²˜ë¦¬ í¬í•¨)
    correct_normalized = _normalize_answer_for_comparison(problem.correct_answer)
    user_normalized = _normalize_answer_for_comparison(actual_user_answer)
    
    print(f"ğŸ” ë‹µì•ˆ ë¹„êµ: ì •ë‹µ '{problem.correct_answer}' â†’ '{correct_normalized}'")
    print(f"ğŸ” ë‹µì•ˆ ë¹„êµ: í•™ìƒ '{actual_user_answer}' â†’ '{user_normalized}'")
    
    # ê¸°ë³¸ ë¬¸ìì—´ ë§¤ì¹­
    is_correct = correct_normalized == user_normalized
    
    # ìˆ˜í•™ ë‹µì•ˆì˜ ê²½ìš° ìœ ì—°í•œ ë§¤ì¹­ ì ìš©
    if not is_correct and problem.problem_type == "short_answer":
        import re
        
        # ì •ë‹µì—ì„œ ìˆ«ìë‚˜ ìˆ˜ì‹ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        correct_values = re.findall(r'-?\d+(?:\.\d+)?', correct_normalized)
        user_values = re.findall(r'-?\d+(?:\.\d+)?', user_normalized)
        
        # ì¶”ì¶œëœ ìˆ«ìë“¤ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        if correct_values and user_values:
            is_correct = correct_values == user_values
            print(f"ğŸ” ë””ë²„ê·¸: ìˆ˜í•™ ë‹µì•ˆ ë§¤ì¹­ - ì •ë‹µ ìˆ«ì: {correct_values}, í•™ìƒ ìˆ«ì: {user_values}, ê²°ê³¼: {is_correct}")
        
        # ì¶”ê°€ì ìœ¼ë¡œ ì½¤ë§ˆë¡œ ë¶„ë¦¬ëœ ê°’ë“¤ ë¹„êµ (a=3, b=-5 vs 3,-5)
        if not is_correct:
            # ì½¤ë§ˆë¡œ ë¶„ë¦¬í•˜ì—¬ ìˆ«ìë§Œ ì¶”ì¶œ
            correct_parts = [part.strip() for part in correct_normalized.replace('=', ',').split(',')]
            user_parts = [part.strip() for part in user_normalized.split(',')]
            
            correct_nums = []
            user_nums = []
            
            for part in correct_parts:
                nums = re.findall(r'-?\d+(?:\.\d+)?', part)
                correct_nums.extend(nums)
            
            for part in user_parts:
                nums = re.findall(r'-?\d+(?:\.\d+)?', part)
                user_nums.extend(nums)
            
            is_correct = correct_nums == user_nums
            print(f"ğŸ” ë””ë²„ê·¸: ì½¤ë§ˆ ë¶„ë¦¬ ë§¤ì¹­ - ì •ë‹µ ìˆ«ì: {correct_nums}, í•™ìƒ ìˆ«ì: {user_nums}, ê²°ê³¼: {is_correct}")
    score = points_per_problem if is_correct else 0
    
    return {
        "problem_id": problem.id,
        "problem_type": problem.problem_type,
        "user_answer": user_answer,  # ì›ë˜ ì‚¬ìš©ì ì…ë ¥ (A, B, C, D)
        "actual_user_answer": actual_user_answer,  # ë³€í™˜ëœ ì‹¤ì œ ë‹µì•ˆ ë‚´ìš©
        "correct_answer": problem.correct_answer,
        "is_correct": is_correct,
        "score": score,
        "points_per_problem": points_per_problem,
        "explanation": problem.explanation
    }


@celery_app.task(bind=True, name="app.tasks.get_task_status")
def get_task_status(self, task_id: str):
    """íƒœìŠ¤í¬ ìƒíƒœ ì¡°íšŒ"""
    from celery.result import AsyncResult
    
    result = AsyncResult(task_id, app=celery_app)
    
    return {
        "task_id": task_id,
        "status": result.status,
        "result": result.result if result.successful() else None,
        "info": result.info
    }